{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nimport pandas as pd\nimport os\n\nfrom tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.models import Model,Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nimport keras\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom tensorflow.keras.applications import VGG16,ResNet101,ResNet101V2, InceptionResNetV2,NASNetLarge,Xception","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd /","execution_count":6,"outputs":[{"output_type":"stream","text":"/\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cd kaggle/input/hackerearth-deep-learning-identify-the-snake-breed/dataset","execution_count":28,"outputs":[{"output_type":"stream","text":"/kaggle/input/hackerearth-deep-learning-identify-the-snake-breed/dataset\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def addext(nm):\n    return nm+'.jpg'","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['image_id'] = train['image_id'].apply(addext)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['image_id'] = test['image_id'].apply(addext)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1/255,\n        #validation_split=0.10,\n        rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest') ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = datagen.flow_from_dataframe(\n        dataframe=train,\n        directory=\"./train/\",\n        x_col=\"image_id\",\n        y_col=\"breed\",\n        subset=\"training\",\n        batch_size=54,\n        seed=42,\n        shuffle=True,\n        color_mode=\"rgb\",\n        class_mode=\"categorical\", # this does the work of encoding\n        target_size=(224,224))","execution_count":18,"outputs":[{"output_type":"stream","text":"Found 5508 validated image filenames belonging to 35 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_datagen = datagen.flow_from_dataframe(\n        dataframe=train,\n        directory=\"./train/\",\n        x_col=\"image_id\",\n        y_col=\"breed\",\n        subset=\"validation\",\n        batch_size=54,\n        seed=42,\n        shuffle=True,\n        color_mode=\"rgb\",\n        class_mode=\"categorical\", # this does the work of encoding\n        target_size=(224,224))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#base_model = EfficientNetB7(weights='imagenet',input_shape=(224,224,3),include_top=False,pooling='avg')\n#base_model = ResNet101(weights='imagenet',input_shape=(224,224,3),include_top=False,pooling='avg')\nbase_model = ResNet101V2(weights='imagenet',input_shape=(224,224,3),include_top=False,pooling='avg')\n#base_model = Xception(weights='imagenet',input_shape=(224,224,3),include_top=False,pooling='avg')\n#base_model = NASNetLarge(weights='imagenet',input_shape=(224,224,3),include_top=False,pooling='avg')\n#base_model = InceptionResNetV2(weights='imagenet',input_shape=(224,224,3),include_top=False,pooling='avg')\n\n#base_model.trainable = False\nfor layer in base_model.layers[:-3]:\n    layer.trainable = False\nfor layer in base_model.layers[-3:]:\n    layer.trainable = True\nmodel = Sequential([\n  base_model, \n  Dense(1024, activation='relu'),\n  Dropout(0.3),\n  Dense(512,activation = 'relu'),\n  Dropout(0.3),\n  Dense(256, activation='relu'),\n  Dropout(0.3),\n  Dense(128, activation = 'relu'),\n  Dense(35, activation='softmax'),\n])","execution_count":19,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n171319296/171317808 [==============================] - 6s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = keras.optimizers.RMSprop(learning_rate=0.0008, decay = 1e-7)\nmodel.compile(optimizer=optimizer,loss =\"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_datagen,epochs=20, \n                    #validation_data=valid_datagen, validation_steps=20,\n                    steps_per_epoch=81)","execution_count":29,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n81/81 [==============================] - 54s 665ms/step - loss: 1.7980 - accuracy: 0.4979\nEpoch 2/20\n81/81 [==============================] - 54s 665ms/step - loss: 1.8012 - accuracy: 0.4947\nEpoch 3/20\n81/81 [==============================] - 54s 661ms/step - loss: 1.7662 - accuracy: 0.5096\nEpoch 4/20\n81/81 [==============================] - 53s 651ms/step - loss: 1.7766 - accuracy: 0.4911\nEpoch 5/20\n81/81 [==============================] - 53s 656ms/step - loss: 1.8031 - accuracy: 0.4936\nEpoch 6/20\n81/81 [==============================] - 53s 657ms/step - loss: 1.7857 - accuracy: 0.4947\nEpoch 7/20\n81/81 [==============================] - 52s 646ms/step - loss: 1.7683 - accuracy: 0.5034\nEpoch 8/20\n81/81 [==============================] - 54s 661ms/step - loss: 1.7527 - accuracy: 0.5062\nEpoch 9/20\n81/81 [==============================] - 53s 655ms/step - loss: 1.7533 - accuracy: 0.5085\nEpoch 10/20\n81/81 [==============================] - 52s 648ms/step - loss: 1.7071 - accuracy: 0.5128\nEpoch 11/20\n81/81 [==============================] - 53s 654ms/step - loss: 1.7543 - accuracy: 0.5080\nEpoch 12/20\n81/81 [==============================] - 53s 651ms/step - loss: 1.7294 - accuracy: 0.5155\nEpoch 13/20\n81/81 [==============================] - 52s 639ms/step - loss: 1.6943 - accuracy: 0.5178\nEpoch 14/20\n81/81 [==============================] - 54s 661ms/step - loss: 1.6924 - accuracy: 0.5165\nEpoch 15/20\n81/81 [==============================] - 53s 655ms/step - loss: 1.6794 - accuracy: 0.5279\nEpoch 16/20\n81/81 [==============================] - 53s 651ms/step - loss: 1.6956 - accuracy: 0.5169\nEpoch 17/20\n81/81 [==============================] - 54s 662ms/step - loss: 1.7091 - accuracy: 0.5299\nEpoch 18/20\n81/81 [==============================] - 53s 658ms/step - loss: 1.6681 - accuracy: 0.5199\nEpoch 19/20\n81/81 [==============================] - 53s 650ms/step - loss: 1.6981 - accuracy: 0.5302\nEpoch 20/20\n81/81 [==============================] - 53s 650ms/step - loss: 1.6737 - accuracy: 0.5283\n","name":"stdout"},{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fccc41130d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('test.csv')\ntest_df[\"image_id\"]=test_df[\"image_id\"].apply(addext)\ntest_datagen = ImageDataGenerator(rescale=1./255,)\ntest_generator=test_datagen.flow_from_dataframe(dataframe=test_df,\n                                            directory=\"test/\",\n                                            x_col=\"image_id\",\n                                            y_col=None,\n                                            batch_size=128,\n                                            seed=42,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(331,331))\n","execution_count":22,"outputs":[{"output_type":"stream","text":"Found 2361 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict_generator(test_generator,verbose=1)\ny_pred_2=np.argmax(y_pred,axis=1)\nlabels = (train_datagen.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in y_pred_2]\ntest_df=pd.read_csv('test.csv')\ntest_name=test_df['image_id'].values\ndata=pd.DataFrame((zip(test_name,predictions)),columns=['image_id','breed'])","execution_count":30,"outputs":[{"output_type":"stream","text":"19/19 [==============================] - 13s 686ms/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd /","execution_count":31,"outputs":[{"output_type":"stream","text":"/\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd kaggle/working","execution_count":32,"outputs":[{"output_type":"stream","text":"/kaggle/working\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('resnet101V2.csv',index = False)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd /","execution_count":27,"outputs":[{"output_type":"stream","text":"/\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}