{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport os\n\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import  MaxPooling2D, Dropout\n\nfrom keras.models import Model\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.resnet50 import preprocess_input,decode_predictions\nfrom keras.preprocessing import image\nimport efficientnet.keras as efn\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We'll change the name of image id with image extensions\ndf = pd.read_csv('train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# small function to append extension \ndef append_ext(fn):\n    return fn+\".jpg\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"image_id\"]=df[\"image_id\"].apply(append_ext)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is used for data augmentation, data flow without taking up too much memory,resizing the images\n# as well and splitting into training and validation sets and coverting labels to categorical values\ndatagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        featurewise_center= False,\n        featurewise_std_normalization=False,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        vertical_flip=True,\n        horizontal_flip=True,\n        zca_epsilon=1e-06,\n        brightness_range = (0.1,0.3),\n        validation_split = 0.20) # comment this line in case of inceptionv3 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Augmentor for train.csv , flow from dataframe will read each image name from dataframe and take \n# the corresponding image directly from directory\ntrain_generator=datagen.flow_from_dataframe(\n        dataframe=df,\n        directory=\"./train/\",\n        x_col=\"image_id\",\n        y_col=\"breed\",\n        subset=\"training\",\n        batch_size=54,\n        seed=42,\n        shuffle=True,\n        color_mode=\"rgb\",\n        class_mode=\"categorical\", # this does the work of encoding\n        target_size=(224,224)) # change the lines as per input dimension of the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Do not run this in case of inception v3\nvalid_generator=datagen.flow_from_dataframe(\n        dataframe=df,\n        directory=\"./train/\",\n        x_col=\"image_id\",\n        y_col=\"breed\",\n        subset=\"validation\",\n        batch_size=54,\n        seed=42,\n        shuffle=True,\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        target_size=(224,224)) # change this line as per dimensions of each model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model =   applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n#base_model =   applications.InceptionV3(weights='imagenet', include_top= False)\n#base_model =   applications.VGG16(weights='imagenet', include_top= True)\n#base_model =   applications.InceptionResNetV2(weights='imagenet', include_top= True)\n#base_model = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In cases where we do not use the top layer\nadd_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dropout(0.3))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dropout(0.3))\nadd_model.add(Dense(128, activation='relu'))\nadd_model.add(Dropout(0.3))\nadd_model.add(Dense(35, activation='softmax'))\n\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n#              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For efficientNet\nfor layer in base_model.layers:\n    layer.trainable = False\nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\npredictions = Dense(35, activation=\"sigmoid\")(x)\nmodel_final = Model(inputs = model.input, outputs = predictions)\nmodel_final.compile(optimizers.RMSprop(lr=0.0001, decay=1e-6),loss='binary_crossentropy',metrics=['accuracy'])\neff_history = model_final.fit_generator(train_generator, steps_per_epoch = 81, epochs = 25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use this for resnet and its derivatives\nx=Base_Model.layers[-2].output\nfc1=Dense(35,activation='softmax')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model=Model(inputs=base_model.input,outputs=fc1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adam works just as well, did not get good yeild from SGD in this case\nfrom keras.optimizers import RMSprop\noptimizer=RMSprop(lr=0.0001, decay=1e-6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optimizers.SGD(lr=1e-4, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make the layers untrainable 48 is for InceptionV3\n# 164 for inception resnetV2\n# 50 for resnet50\n# 16 for vgg\n# This makes sure that the layers do not get changed during training\nfor l in my_model.layers[:-48]:\n    #print(l)\n    l.trainable = False\n    \nmy_model.compile(optimizer=optimizer,loss =\"categorical_crossentropy\",\n                 metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd kaggle/input/hackerearths-snakes-in-the-hood/dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model.fit_generator(train_generator,epochs=25,\n                       #validation_data=valid_generator,\n                       #validation_steps=20,\n                       steps_per_epoch=5508//128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"image_id\"]=test_df[\"image_id\"].apply(append_ext)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255,)\n\ntest_generator=test_datagen.flow_from_dataframe(dataframe=test_df,\n                                            directory=\"test/\",\n                                            x_col=\"image_id\",\n                                            y_col=None,\n                                            batch_size=128,\n                                            seed=42,\n                                            shuffle=False,\n                                            class_mode=None,\n                                            target_size=(331,331))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the output\ny_pred=my_model.predict_generator(test_generator,verbose=1)\ny_pred_2=np.argmax(y_pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare for saving\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in y_pred_2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('test.csv')\ntest_name=test_df['image_id'].values\ndata=pd.DataFrame((zip(test_name,predictions)),columns=['image_id','breed'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use cd / before this is it doesnt work, we need to go to wokring directory of kaggle to save\ncd kaggle/working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv('output3.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is observed that inceptionV3 and InceptionResnetV2 give the best outputs for 25 epochs,\nSelf created CNN did not give accuracy above 9% whatsoever hence transfer learning was saught after.\nMethods and Models used here are referred from documentations and examples as available \nFurther comments and suggestions are welcome.....questions if any are also welcome"},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}