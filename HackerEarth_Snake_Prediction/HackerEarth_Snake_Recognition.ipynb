{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data needs to be preprocessed, we need to make new folders for each species and \n",
    "# Shift the corresponding image to the respcetive folder\n",
    "dataset = pd.read_csv('dataset/train.csv')\n",
    "file_names = list(dataset['image_id'].values)\n",
    "img_labels = list(dataset['breed'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(np.unique(dataset['breed'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = os.getcwd()\n",
    "\n",
    "for new_path in lst:\n",
    "    if not os.path.exists(\".\" + new_path):\n",
    "        os.makedirs(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = lst.copy()\n",
    "\n",
    "for f in range(len(file_names)):\n",
    "    current_img = file_names[f]\n",
    "    current_label = img_labels[f]\n",
    "    shutil.move(\"dataset//train//\"+current_img+\".jpg\", current_label+\"//\"+current_img+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in os.listdir(\"data\"):\n",
    "    for image in os.listdir(\"data//\"+label):\n",
    "        img = cv2.resize(cv2.imread(\"data//\"+label+\"//\"+image),(128,128))\n",
    "        cv2.imwrite(\"data//\"+label+\"//\"+image,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here we start building the image classifier.\n",
    "# The preprocessing will allow us to use data flow from directry function so as to reduce time consumption \n",
    "# And enable data augmentation\n",
    "# Each image is resized to fit 128x128 and retained all the 3 layers for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        zca_epsilon=1e-06,\n",
    "        brightness_range = (0.1,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5508 images belonging to 35 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = train_datagen.flow_from_directory(\n",
    "        'data',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=128,\n",
    "        class_mode='categorical',\n",
    "        color_mode=\"rgb\",\n",
    "        shuffle=True,\n",
    "    seed=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import  Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import applications \n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model and start building the cnn\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2D( number_of_filters , kernal_size , input_shape(add this parameter just for the input conv layer))\n",
    "model.add(Conv2D(64 , (3,3) , input_shape = (128,128,3) ))\n",
    "# define the activaion function for this layer\n",
    "model.add(Activation('relu'))\n",
    "# define the pooling for this layer\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64 , (3,3) ))\n",
    "# define the activaion function for this layer\n",
    "model.add(Activation('relu'))\n",
    "# define the pooling for this layer\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32 , (3,3) ))\n",
    "# define the activaion function for this layer\n",
    "model.add(Activation('relu'))\n",
    "# define the pooling for this layer\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(35))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', \n",
    "                optimizer = 'adam', \n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit_generator(\n",
    "    gen,\n",
    "    steps_per_epoch=5,\n",
    "    epochs=10)\n",
    "end = time.time()\n",
    "print('Processing time:',(end - start)/60)\n",
    "model.save_weights('model_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
